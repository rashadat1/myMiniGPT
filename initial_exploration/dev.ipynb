{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "with open('/Users/tarikrashada/Projects/myMiniGPT/data/input.txt','r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600901\n"
     ]
    }
   ],
   "source": [
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz¤¦©«Ã†\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the possible characters are model can emit. \n",
    "# We need to develop a strategy to tokenize the text - \n",
    "# convert the raw text to some sequence of integers according \n",
    "# to some vocabulary\n",
    "\n",
    "# the simplest tokenization procedure would be character tokenization\n",
    "# in practice LLMs have tokenizers that are optimized a lot better\n",
    "# our character tokenizer will only have 85 integers but real\n",
    "# tokenizers like tiktoken produce 10s of thousands of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_int_map = {char : i for i,char in enumerate(chars)}\n",
    "int_to_char_map = {i : char for i,char in enumerate(chars)}\n",
    "def encode(s):\n",
    "    return [char_to_int_map[s[i]] for i in range(len(s))]\n",
    "def decode(int_list):\n",
    "    return ''.join([int_to_char_map[k] for k in int_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text),dtype=torch.long)\n",
    "# data is the complete tokenized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will now split the data into train and validation sets. We will make the first 90% of the data\n",
    "# train and the rest will be for validation\n",
    "num = int(0.9*len(data))\n",
    "train_data = data[:num]\n",
    "val_data = data[num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38, 42, 32, 37,\n",
       "        30,  1, 72, 60, 53, 72,  1, 43, 70, 73, 72, 60,  1, 61, 71])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next we need to break the train data into context windows and also batches \n",
    "batch_size = 16\n",
    "context_length = 32\n",
    "\n",
    "train_data[:context_length+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The context tensor([39]) is used to predict target: 41\n",
      "The context tensor([39, 41]) is used to predict target: 28\n",
      "The context tensor([39, 41, 28]) is used to predict target: 29\n",
      "The context tensor([39, 41, 28, 29]) is used to predict target: 24\n",
      "The context tensor([39, 41, 28, 29, 24]) is used to predict target: 26\n",
      "The context tensor([39, 41, 28, 29, 24, 26]) is used to predict target: 28\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28]) is used to predict target: 0\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0]) is used to predict target: 0\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0]) is used to predict target: 0\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0]) is used to predict target: 42\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42]) is used to predict target: 44\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44]) is used to predict target: 39\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39]) is used to predict target: 39\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39]) is used to predict target: 38\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38]) is used to predict target: 42\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38, 42]) is used to predict target: 32\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38, 42, 32]) is used to predict target: 37\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38, 42, 32, 37]) is used to predict target: 30\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38, 42, 32, 37,\n",
      "        30]) is used to predict target: 1\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38, 42, 32, 37,\n",
      "        30,  1]) is used to predict target: 72\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38, 42, 32, 37,\n",
      "        30,  1, 72]) is used to predict target: 60\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38, 42, 32, 37,\n",
      "        30,  1, 72, 60]) is used to predict target: 53\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38, 42, 32, 37,\n",
      "        30,  1, 72, 60, 53]) is used to predict target: 72\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38, 42, 32, 37,\n",
      "        30,  1, 72, 60, 53, 72]) is used to predict target: 1\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38, 42, 32, 37,\n",
      "        30,  1, 72, 60, 53, 72,  1]) is used to predict target: 43\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38, 42, 32, 37,\n",
      "        30,  1, 72, 60, 53, 72,  1, 43]) is used to predict target: 70\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38, 42, 32, 37,\n",
      "        30,  1, 72, 60, 53, 72,  1, 43, 70]) is used to predict target: 73\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38, 42, 32, 37,\n",
      "        30,  1, 72, 60, 53, 72,  1, 43, 70, 73]) is used to predict target: 72\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38, 42, 32, 37,\n",
      "        30,  1, 72, 60, 53, 72,  1, 43, 70, 73, 72]) is used to predict target: 60\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38, 42, 32, 37,\n",
      "        30,  1, 72, 60, 53, 72,  1, 43, 70, 73, 72, 60]) is used to predict target: 1\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38, 42, 32, 37,\n",
      "        30,  1, 72, 60, 53, 72,  1, 43, 70, 73, 72, 60,  1]) is used to predict target: 61\n",
      "The context tensor([39, 41, 28, 29, 24, 26, 28,  0,  0,  0, 42, 44, 39, 39, 38, 42, 32, 37,\n",
      "        30,  1, 72, 60, 53, 72,  1, 43, 70, 73, 72, 60,  1, 61]) is used to predict target: 71\n"
     ]
    }
   ],
   "source": [
    "# this is the first 17 characters. When we sample a chunk of data like this, this actually has multiple\n",
    "# examples packed. We want our transformer to be able to make predictions with contexts of length up to 32\n",
    "\n",
    "# it should still be able to make predictions with a context of less than this. E.g.\n",
    "\n",
    "for t in range(context_length):\n",
    "    x = data[:t+1]\n",
    "    y = data[t+1]\n",
    "    \n",
    "    print(f\"The context {x} is used to predict target: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so context length is the maximum context length for predictions while batch_size is the number of\n",
    "# independent sequences processed in parallel\n",
    "\n",
    "def generate_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    # generate batch size number of random positions between 0 and len(data) - context_length\n",
    "    xi = torch.randint(len(data) - context_length, (batch_size,))\n",
    "    # the first 'context_length' characters starting at i\n",
    "    x = torch.stack([data[i:i + context_length] for i in xi])\n",
    "    # the y's are the offset 1 of this\n",
    "    y = torch.stack([data[i + 1: i + 1 + context_length] for i in xi])\n",
    "    return x,y\n",
    "\n",
    "# y gives us the correct answer for every position in x (it is the next token that we would be predicting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding_lookup = nn.Embedding(vocab_size, vocab_size)\n",
    "    # thin wrapper where we basically convert each integer in our input to the integer-th row of the\n",
    "    # embedding matrix\n",
    "    def forward(self, input, targets=None):\n",
    "        logits = self.embedding_lookup(input) # <- shape is (batch_size, context_length, vocab_size)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            \n",
    "        return logits, loss\n",
    "        # because the final dimension is vocab size we can interpret this to be the scores or logits for the\n",
    "        # next char in the sequence - for each of the inputs we have vocab_size scores because there are\n",
    "        # batch_size * context_length predictions\n",
    "    def generate(self, input, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get predictions\n",
    "            logits, _ = self(input)\n",
    "            # focus on last time step because this is the prediction using the entire context window\n",
    "            logits = logits[:,-1,:]\n",
    "            # softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample from distribution to get 1 sample\n",
    "            next = torch.multinomial(probs, num_samples=1) # <- (batch_size, 1)\n",
    "            input = torch.cat((input, next), dim=1) # <- (B, context_length + 1) concatenate the new token\n",
    "        return input\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = generate_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 85])\n",
      "tensor(4.8055, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Bigram = BigramLanguageModel(vocab_size)\n",
    "logits, loss = Bigram(xb,yb)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny4Zh;\"MM;1?42h16e2\"d\\nsoZedRkt?6iPsnUFQAHRÃ9U©H]V=n¤GA??(XlKH.†xIRV4OeVUG[2I=1Nh©28G 8qc2_2]JSTLY?DGs'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.zeros((1,1),dtype=torch.long)\n",
    "decode(Bigram.generate(output,max_new_tokens=100)[0].tolist())\n",
    "# the output is random because the embedding weights are initially random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(Bigram.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Bigram\n",
    "\n",
    "\n",
    "batch_size\n",
    "for steps in range(10000):\n",
    "    xb, yb = generate_batch('train')\n",
    "    # evaluate loss\n",
    "    logits, loss = Bigram(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nat n hed\\nith \" lewid.\\natabus (fbe th k tit icoregsthaphast. id ipaniell Gathe t\\nheere iopeMIANe acev'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(Bigram.generate(output,max_new_tokens=100)[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find a way to include data from every token prior to the token we are currently processing. We want to calculate something like an average of all of the embeddings of previous tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can model this using matrix multiplication with lower triangular matrices and performing an average in the rows of the resulting matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g.\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 1.],\n",
       "        [2., 4.],\n",
       "        [2., 5.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0000, 1.0000],\n",
       "        [3.5000, 2.5000],\n",
       "        [3.0000, 3.3333]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the result is that each row of c is an average of the rows of b\n",
    "# the first row averages the first row\n",
    "# the second row averages the first two rows\n",
    "# the third row averages all three rows of b\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is analogous to self-attention - we weight some vectors associated with each of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tril = torch.tril(torch.ones(5,5))\n",
    "wei = torch.zeros((5,5))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei\n",
    "# the lower triangular shape lets us mask out and normalize the token embeddings so that \n",
    "# we only calculate affinities amongst tokens that occur before a given token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a very obvious problem here that we don't want these scores to be equally weighted across all previous tokens. We want to choose weights in a data dependent way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-attention solves this with the following - each token at each position will emit a key vector and a query vector. For a given token - the dot product is calculated between the key vector of this token and the query vector of all other past tokens. If the dot product is large then we say it has a strong affinity to the token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing this dot product we normalize to get what we call attention scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-attention for a single attention head\n",
    "head_dim = 16\n",
    "embed_dim = 32\n",
    "# x1 contains the positional + token embeddings and it is the combined positional and token\n",
    "# embedding for all elements in a sequence (1 batch)\n",
    "x1 = torch.randn(batch_size,context_length,embed_dim)\n",
    "\n",
    "key_Matrix = nn.Linear(embed_dim,head_dim,bias=False)\n",
    "query_Matrix = nn.Linear(embed_dim,head_dim,bias=False)\n",
    "\n",
    "key_vec1 = key_Matrix(x1)\n",
    "query_vec2 = query_Matrix(x1)\n",
    "\n",
    "wei = query_vec2 @ key_vec1.transpose(-2,-1) # output is (batch_size,context_length,context_length)\n",
    "\n",
    "tril = torch.tril(torch.ones(context_length,context_length))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim= -1)\n",
    "\n",
    "# wei has shape batch_size, context_length, context_length\n",
    "# and will have zeros above the major diagonal (it is lower triagonal)\n",
    "# because of the tril mask so that only prior token embeddings have influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [9.4236e-01, 5.7643e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [4.3725e-02, 1.5580e-01, 8.0048e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [6.0430e-02, 2.8321e-02, 3.9269e-02,  ..., 1.5843e-02,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [1.2855e-02, 2.6191e-03, 4.9429e-03,  ..., 2.8759e-02,\n",
       "          1.0886e-02, 0.0000e+00],\n",
       "         [3.1368e-02, 1.2411e-03, 1.2391e-02,  ..., 4.8287e-02,\n",
       "          1.3204e-02, 1.6809e-02]],\n",
       "\n",
       "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [9.0805e-01, 9.1946e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [8.9412e-03, 9.7391e-01, 1.7153e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [2.8447e-03, 7.3581e-02, 2.1818e-02,  ..., 8.9623e-04,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [5.6102e-03, 2.7844e-03, 6.2424e-02,  ..., 1.1799e-01,\n",
       "          6.1197e-02, 0.0000e+00],\n",
       "         [3.3424e-02, 1.8634e-03, 2.3664e-02,  ..., 3.5649e-02,\n",
       "          8.7206e-02, 1.3614e-02]],\n",
       "\n",
       "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [5.5670e-01, 4.4330e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [4.0088e-01, 2.5664e-01, 3.4248e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [1.5217e-02, 3.1470e-03, 1.9924e-02,  ..., 1.4349e-02,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [3.9247e-02, 1.1877e-02, 1.1806e-02,  ..., 2.1561e-02,\n",
       "          1.2655e-02, 0.0000e+00],\n",
       "         [1.4163e-02, 9.2564e-04, 6.9456e-03,  ..., 1.4444e-03,\n",
       "          5.3858e-03, 2.5417e-03]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [6.5888e-01, 3.4112e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [7.4879e-02, 4.9504e-01, 4.3008e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [3.3033e-02, 4.8854e-03, 1.0305e-01,  ..., 6.0136e-03,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [6.4608e-03, 3.3696e-02, 2.9894e-03,  ..., 7.1651e-04,\n",
       "          4.5141e-04, 0.0000e+00],\n",
       "         [5.7777e-03, 7.1776e-02, 2.4881e-02,  ..., 1.6939e-02,\n",
       "          8.0135e-03, 1.2850e-02]],\n",
       "\n",
       "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [4.6464e-01, 5.3536e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [3.6012e-01, 2.2695e-01, 4.1293e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [1.4663e-02, 6.2416e-02, 1.0713e-02,  ..., 1.4659e-02,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [5.6924e-02, 1.3085e-02, 4.5201e-02,  ..., 1.5863e-02,\n",
       "          4.2854e-02, 0.0000e+00],\n",
       "         [7.0132e-02, 4.3501e-02, 9.1400e-02,  ..., 5.3382e-03,\n",
       "          7.3737e-03, 1.5697e-02]],\n",
       "\n",
       "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [5.0095e-01, 4.9905e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [2.6284e-01, 4.6504e-01, 2.7211e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [7.7101e-03, 1.2895e-02, 2.1520e-02,  ..., 2.3886e-02,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [2.3998e-03, 1.6828e-02, 3.0068e-02,  ..., 3.4853e-02,\n",
       "          1.6244e-02, 0.0000e+00],\n",
       "         [1.4523e-03, 2.8442e-02, 2.1701e-02,  ..., 1.0099e-02,\n",
       "          3.4404e-03, 2.5268e-02]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
